name: Automated Testing Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Run daily at 2 AM UTC
    - cron: '0 2 * * *'

env:
  NODE_VERSION: '18'
  PYTHON_VERSION: '3.11'

jobs:
  # Unit Tests
  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    strategy:
      matrix:
        component: [backend, frontend]
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Backend Environment
        if: matrix.component == 'backend'
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Setup Frontend Environment
        if: matrix.component == 'frontend'
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json
      
      - name: Install Backend Dependencies
        if: matrix.component == 'backend'
        run: |
          cd backend
          pip install -e .
          pip install pytest pytest-cov pytest-xdist
      
      - name: Install Frontend Dependencies
        if: matrix.component == 'frontend'
        run: |
          cd frontend
          npm ci
      
      - name: Run Backend Unit Tests
        if: matrix.component == 'backend'
        run: |
          cd backend
          pytest tests/ -v --cov=app --cov-report=xml --cov-report=html --junit-xml=test-results.xml
      
      - name: Run Frontend Unit Tests
        if: matrix.component == 'frontend'
        run: |
          cd frontend
          npm run test:unit -- --coverage --reporter=junit --outputFile=test-results.xml
      
      - name: Upload Coverage Reports
        uses: codecov/codecov-action@v3
        with:
          file: ./${{ matrix.component }}/coverage.xml
          flags: ${{ matrix.component }}-unit
          name: ${{ matrix.component }}-unit-coverage
      
      - name: Upload Test Results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: ${{ matrix.component }}-unit-test-results
          path: ${{ matrix.component }}/test-results.xml

  # Integration Tests
  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: unit-tests
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: testpass
          POSTGRES_DB: testdb
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      
      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json
      
      - name: Install Dependencies
        run: |
          cd backend && pip install -e . && pip install pytest pytest-asyncio
          cd ../frontend && npm ci
      
      - name: Setup Test Database
        run: |
          cd backend
          python -c "
          import os
          os.environ['DATABASE_URL'] = 'postgresql://postgres:testpass@localhost:5432/testdb'
          from alembic.config import Config
          from alembic import command
          alembic_cfg = Config('alembic.ini')
          alembic_cfg.set_main_option('sqlalchemy.url', os.environ['DATABASE_URL'])
          command.upgrade(alembic_cfg, 'head')
          "
        env:
          DATABASE_URL: postgresql://postgres:testpass@localhost:5432/testdb
      
      - name: Run Integration Tests
        run: |
          cd backend
          python run_integration_tests.py --junit-xml=integration-results.xml
        env:
          DATABASE_URL: postgresql://postgres:testpass@localhost:5432/testdb
          REDIS_URL: redis://localhost:6379
      
      - name: Upload Integration Test Results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: integration-test-results
          path: backend/integration-results.xml

  # Performance Tests
  performance-tests:
    name: Performance Tests
    runs-on: ubuntu-latest
    needs: integration-tests
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: testpass
          POSTGRES_DB: testdb
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install Dependencies
        run: |
          cd backend
          pip install -e .
          pip install locust pytest-benchmark
      
      - name: Run Performance Tests
        run: |
          cd backend
          python tests/performance/run_performance_tests.py --output=performance-results.json
        env:
          DATABASE_URL: postgresql://postgres:testpass@localhost:5432/testdb
      
      - name: Check Performance Regression
        run: |
          python scripts/analyze_performance_regression.py \
            --current=backend/performance-results.json \
            --baseline=performance-baseline.json \
            --threshold=0.2
      
      - name: Upload Performance Results
        uses: actions/upload-artifact@v3
        with:
          name: performance-test-results
          path: backend/performance-results.json

  # Security Tests
  security-tests:
    name: Security Tests
    runs-on: ubuntu-latest
    needs: unit-tests
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install Dependencies
        run: |
          cd backend
          pip install -e .
          pip install bandit safety pytest-security
      
      - name: Run Security Tests
        run: |
          cd backend
          python run_security_tests.py --junit-xml=security-results.xml
      
      - name: Run Bandit Security Scan
        run: |
          cd backend
          bandit -r app/ -f json -o bandit-results.json
      
      - name: Upload Security Test Results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: security-test-results
          path: |
            backend/security-results.xml
            backend/bandit-results.json

  # End-to-End Tests
  e2e-tests:
    name: End-to-End Tests
    runs-on: ubuntu-latest
    needs: integration-tests
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: testpass
          POSTGRES_DB: testdb
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          cache: 'npm'
          cache-dependency-path: frontend/package-lock.json
      
      - name: Install Dependencies
        run: |
          cd backend && pip install -e .
          cd ../frontend && npm ci
          npx playwright install --with-deps
      
      - name: Start Application
        run: |
          cd backend && python main.py &
          cd frontend && npm run build && npm run preview &
          sleep 10
        env:
          DATABASE_URL: postgresql://postgres:testpass@localhost:5432/testdb
      
      - name: Run E2E Tests
        run: |
          cd frontend
          npx playwright test --reporter=junit
      
      - name: Upload E2E Test Results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: e2e-test-results
          path: |
            frontend/test-results/
            frontend/playwright-report/

  # Load Tests
  load-tests:
    name: Load Tests
    runs-on: ubuntu-latest
    needs: performance-tests
    if: github.event_name == 'schedule' || contains(github.event.head_commit.message, '[load-test]')
    
    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: testpass
          POSTGRES_DB: testdb
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install Dependencies
        run: |
          cd backend
          pip install -e .
          pip install locust
      
      - name: Run Load Tests
        run: |
          cd backend
          python tests/load/run_load_tests.py --output=load-results.json
        env:
          DATABASE_URL: postgresql://postgres:testpass@localhost:5432/testdb
      
      - name: Upload Load Test Results
        uses: actions/upload-artifact@v3
        with:
          name: load-test-results
          path: backend/load-results.json

  # Generate Test Report
  test-report:
    name: Generate Test Report
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests, performance-tests, security-tests, e2e-tests]
    if: always()
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Download All Test Results
        uses: actions/download-artifact@v3
        with:
          path: test-artifacts/
      
      - name: Install Report Dependencies
        run: |
          pip install jinja2 matplotlib seaborn pandas
      
      - name: Generate Comprehensive Test Report
        run: |
          python scripts/generate_test_report.py \
            --artifacts-dir=test-artifacts/ \
            --output=test-report.html \
            --format=html
      
      - name: Upload Test Report
        uses: actions/upload-artifact@v3
        with:
          name: comprehensive-test-report
          path: test-report.html
      
      - name: Comment PR with Test Results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v6
        with:
          script: |
            const fs = require('fs');
            const reportPath = 'test-report.html';
            if (fs.existsSync(reportPath)) {
              const report = fs.readFileSync(reportPath, 'utf8');
              // Extract summary from HTML report
              const summaryMatch = report.match(/<div class="summary">(.*?)<\/div>/s);
              const summary = summaryMatch ? summaryMatch[1] : 'Test report generated';
              
              github.rest.issues.createComment({
                issue_number: context.issue.number,
                owner: context.repo.owner,
                repo: context.repo.repo,
                body: `## Test Results Summary\n\n${summary}\n\nFull report available in artifacts.`
              });
            }

  # Notify on Failure
  notify-failure:
    name: Notify on Failure
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests, performance-tests, security-tests, e2e-tests]
    if: failure()
    
    steps:
      - name: Send Notification
        run: |
          curl -X POST "${{ secrets.SLACK_WEBHOOK_URL }}" \
            -H 'Content-type: application/json' \
            --data '{
              "text": "ðŸš¨ Automated Testing Pipeline Failed",
              "blocks": [
                {
                  "type": "section",
                  "text": {
                    "type": "mrkdwn",
                    "text": "*Automated Testing Pipeline Failed*\n\nRepository: ${{ github.repository }}\nBranch: ${{ github.ref_name }}\nCommit: ${{ github.sha }}\nWorkflow: ${{ github.workflow }}\n\n<${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}|View Details>"
                  }
                }
              ]
            }'
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}